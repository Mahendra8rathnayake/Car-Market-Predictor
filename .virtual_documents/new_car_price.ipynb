import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

from scikeras.wrappers import KerasRegressor

from scikeras.wrappers import KerasRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.pipeline import Pipeline

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"        # Hide warnings
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"       # Disable certain optimizations
os.environ["TF_DISABLE_META_OPTIMIZER"] = "1"   # Prevent the graph_buf warning

        


df = pd.read_csv('car_price_dataset_medium.csv')


# Check if the dataset loaded correctly

df.head()


# Basic info
df.info()
df.describe()


# Shape of the dataset
df.shape


# Check missing values
df.isnull().sum()



#Check unique values for key columns: (Helps understand categorical columns like brand, model, fuel type.)

df.nunique()



# Distribution of the target variable (Price)

sns.histplot(df['Price_USD'], kde=True)
plt.show()


# Price vs. Mileage / Engine power / Year

#Scatter plot to find price drivers:

sns.scatterplot(data=df, x='Mileage_kmpl', y='Price_USD')
plt.show()






















numeric_df = df.select_dtypes(include=['int64', 'float64'])


# Correlation heatmap (numerical features vs price)

plt.figure(figsize=(12,6))
sns.heatmap(numeric_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.show()



# Outlier detection (Boxplots)
sns.boxplot(x=df['Price_USD'])
plt.show()


numeric_cols = df.select_dtypes(include=np.number).columns
df[numeric_cols].boxplot(figsize=(15,8))
plt.xticks(rotation=45)
plt.show()






# Brand:
df['Brand'].value_counts().head(10)


# Fuel type:
df['Fuel_Type'].value_counts()


# Plot:
sns.countplot(data=df, x='Fuel_Type')
plt.show()





# Define target + features

# Assume target column is "price".

X = df.drop('Price_USD', axis=1)
y = df['Price_USD']


# Split categorical & numerical columns
numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns


# Preprocessing (One-Hot Encoding)
preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numeric_cols)
    ]
)


# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# Build Linear Regression Pipeline
model = Pipeline(steps=[
    ('preprocess', preprocess),
    ('lr', LinearRegression())
])



# Train the model
model.fit(X_train, y_train)


# Predictions
y_pred = model.predict(X_test)


# Evaluation Metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("MAE:", mae)
print("RMSE:", rmse)
print("R2 Score:", r2)





new_car = pd.DataFrame({
    'Brand': ['Honda'],
    'Model_Year': [2019],
    'Kilometers_Driven': [35000],
    'Fuel_Type': ['Petrol'],
    'Transmission': ['Automatic'],
    'Mileage_kmpl': [18],            # FIXED
    'Owner_Type': ['First'],
    'Engine_CC': [1500],
    'Max_Power_bhp': [120],
    'Seats': [5],
    'Car_ID': [0]                    # If your model requires it
})




# Code with Dollar Sign + Rounding
prediction = model.predict(new_car)[0]

# Round and add dollar sign
rounded_price = f"${round(prediction, 2):,}"

print("Predicted Price:", rounded_price)





# Choose a numeric feature to plot against price
feature = 'Engine_CC'  # can also use 'Mileage_kmpl', 'Kilometers_Driven'

# Plot existing dataset
plt.figure(figsize=(10,6))
sns.scatterplot(x=df[feature], y=df['Price_USD'], color='blue', label='Existing Cars')

# Plot new_car prediction
plt.scatter(new_car[feature], rounded_price, color='red', s=200, label='Your Car')

# Add labels
plt.xlabel(feature)
plt.ylabel('Price')
plt.title(f'Price Prediction vs {feature}')
plt.legend()
plt.show()








rf_model = Pipeline(steps=[
    ('preprocess', preprocess),     # same one-hot + numeric passthrough
    ('rf', RandomForestRegressor(
        n_estimators=300,
        max_depth=None,
        random_state=42
    ))
])


# Train the model
rf_model.fit(X_train, y_train)


# Evaluate the model
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

y_pred = rf_model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("Random Forest RMSE:", rmse)
print("Random Forest R² Score:", r2)



# Predict New Car Price

# Use your same new_car DataFrame:

prediction = rf_model.predict(new_car)[0]
rounded_price = round(prediction, 2)

print("Predicted Price using Random Forest: $", rounded_price)






# Predictions
y_pred_lr = model.predict(X_test)        # Linear Regression model
y_pred_rf = rf_model.predict(X_test)     # Random Forest model







import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))

# Scatter actual vs predicted
sns.scatterplot(x=y_test, y=y_pred_lr, label="Linear Regression", alpha=0.6)
sns.scatterplot(x=y_test, y=y_pred_rf, label="Random Forest", alpha=0.6)

# Perfect prediction line
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         color='black', linestyle='--', label="Perfect Fit")

plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Actual vs Predicted Price: Random Forest vs Linear Regression")
plt.legend()
plt.show()








import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# -----------------------------------------------------------
# 1. Separate target and features
# -----------------------------------------------------------
target = "Price_USD"
X = df.drop(columns=[target])
y = df[target]

# -----------------------------------------------------------
# 2. Identify categorical / numeric columns
# -----------------------------------------------------------
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()

# -----------------------------------------------------------
# 3. Preprocess (One-Hot Encode categorical)
# -----------------------------------------------------------
preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numeric_cols)
    ]
)

# Fit + transform full training data
X_processed = preprocess.fit_transform(X)

# -----------------------------------------------------------
# 4. Train-test split
# -----------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, random_state=42
)

# -----------------------------------------------------------
# 5. Build Neural Network
# -----------------------------------------------------------
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1)   # output layer
])

model.compile(optimizer='adam', loss='mse')

# -----------------------------------------------------------
# 6. Train model
# -----------------------------------------------------------
model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)

# -----------------------------------------------------------
# 7. Predict & Evaluate
# -----------------------------------------------------------
y_pred = model.predict(X_test).flatten()

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2   = r2_score(y_test, y_pred)

print("Neural Network RMSE:", rmse)
print("Neural Network R²:", r2)






# -----------------------------
# 1. IMPORT LIBRARIES
# -----------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# -----------------------------
# 2. PREPARE DATA
# -----------------------------
target = "Price_USD"  # Replace with your exact target column name if different
X = df.drop(columns=[target])
y = df[target]

categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()

preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numeric_cols)
    ]
)

X_processed = preprocess.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, random_state=42
)

# -----------------------------
# 3. LINEAR REGRESSION
# -----------------------------
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2_lr   = r2_score(y_test, y_pred_lr)

# -----------------------------
# 4. RANDOM FOREST
# -----------------------------
rf_model = RandomForestRegressor(n_estimators=200, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf   = r2_score(y_test, y_pred_rf)

# -----------------------------
# 5. NEURAL NETWORK
# -----------------------------
input_dim = X_train.shape[1]

nn_model = Sequential([
    Dense(64, activation='relu', input_shape=(input_dim,)),
    Dense(32, activation='relu'),
    Dense(1)
])

nn_model.compile(optimizer='adam', loss='mse')
nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)  # verbose=0 to reduce logs

y_pred_nn = nn_model.predict(X_test).flatten()

rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))
r2_nn   = r2_score(y_test, y_pred_nn)

# -----------------------------
# 6. PRINT METRICS
# -----------------------------
print("Linear Regression -> RMSE: {:.2f}, R²: {:.2f}".format(rmse_lr, r2_lr))
print("Random Forest     -> RMSE: {:.2f}, R²: {:.2f}".format(rmse_rf, r2_rf))
print("Neural Network    -> RMSE: {:.2f}, R²: {:.2f}".format(rmse_nn, r2_nn))

# -----------------------------
# 7. VISUAL COMPARISON
# -----------------------------
plt.figure(figsize=(12,6))
plt.scatter(y_test, y_pred_lr, color='blue', alpha=0.6, label='Linear Regression')
plt.scatter(y_test, y_pred_rf, color='green', alpha=0.6, label='Random Forest')
plt.scatter(y_test, y_pred_nn, color='red', alpha=0.6, label='Neural Network')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Model Comparison: Predicted vs Actual Price')
plt.legend()
plt.show()







